---
title: "Homework 1"
author: "Group 1"
date: ''
output:
  pdf_document:
    includes:
      in_header: header.tex
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
---

\begin{center}
\bigskip
\bigskip
\bigskip
Prepared for:\\
\medskip
Dr. Nathan Bastian\\
\smallskip
City University of New York, School of Professional Studies - Data 621\\
\bigskip
Prepared by:\\
\medskip
Group 1\\ 
\medskip
Senthil Dhanapal\\ 
\smallskip
Yadu Chittampalli\\
\smallskip
Christophe Hunt\\  

\end{center}

```{r, include = FALSE}
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr, 
       stringr, e1071, corrplot, knitcitations, bibtex, missForest,
       foreach, doParallel, stargazer, forecast)
```

```{r, include=FALSE, cache=TRUE}
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", 
              destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
data_dictionary <- read.xlsx("Data Dictionary HW1 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW1 - Group 1", full.names = TRUE))
```
\newpage


# Introduction

The ability to analyize and predict performance of a professional baseball team using many dimensions is critical to competitive success for our organization. Therefore, we have analyzed the records of numerous professional baseball team from the years 1871 to 2006. Our hope is that the following report and the resulting predictive models will better inform the organization and assist in making data driven decisions moving forward. 

"The goal of a baseball team is to win more games than any other team. Since one team has very little control over the number of games other teams win, the goal is essentially to win as many games as possible. Therefore, it is of interest to measure the player's contribution to the team's wins." Grabiner, B. D. [^1] While we do not have the variables at the player's individual contribution level, we do have the entire teams contributions as an aggregate and will analyze that information. 

[^1]: (Grabiner, B. D. (n.d.). [The Sabermetric Manifesto.](http://seanlahman.com/baseball-archive/sabermetrics/sabermetric-manifesto/) Retrieved September 10, 2016 from http://seanlahman.com/baseball-archive/sabermetrics/sabermetric-manifesto/) 

# Statement of the Problem

The purpose of this report is to determine the batting, baserun, pitching, and fielding effects on a baseball team's ability to win.  

# Data Exploration  

Note that each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season. The following Table 1 - Descriptive Statistics provides the detailed descriptive statistics regarding our variable of interest - Number of Wins and our possible explanatory variables. 

We noted that several variables were missing a nontrivial amount of observations and these variables are Strikeouts by batters, Stolen Bases, Caught stealing, Batters hit by pitch (get a free base), Strikeouts by pitcher, and Double plays. So we will need to address the missing values for further analysis. 

Histograms of all of the variables have been plotted below so that the distribution of the data can be visualized. In the distribution for the number of walks allowed, only two bars exist due to the excessive number of outliers.

```{r, echo=FALSE, results='asis', cache=TRUE}
df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/moneyball-training-data.csv")

colnames(df) <- mapvalues(as.vector(colnames(df)), 
                            from = str_trim(data_dictionary$VARIABLE.NAME..), to = as.vector(str_trim(data_dictionary$DEFINITION)))

digits <- c(1) 

descriptive <- describe(df %>% select(-`Identification Variable (do not use)`), 
                        descript = "Table 1 : Descriptive Statistics", digits = digits) 

for (i in seq(1:length(descriptive))){ 
                     for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
                                         }
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
     
     descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[7] <- "Median"
     
     descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[8] <- "SD"
     
     descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[9] <- "Skew"
     
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder 
}

latex(descriptive, file = '')
```

## Imputing Missing Values  

In order to address the missing values in our variables we used a nonparametric imputation method (Random Forest) to impute missing values. Several variables have a significant amount of skew, which include the number of base hits by batters and the number of walks allowed. Correspondingly, these two variables had a skew of 1.57 and 6.74 respectively. Therefore, we chose a nonparametric method due to several variables having significant skew and having a non-normal distribution. 

\newpage 

```{r, results='asis', echo = FALSE, include=FALSE, cache=TRUE, eval=FALSE}
registerDoParallel(cl = makeCluster(2), cores = 3)

set.seed(1234)

imputed_data <- df %>% 
              select(-`Identification Variable (do not use)`) %>%
              missForest(maxiter = 10, ntree = 100, parallelize = 'forests')

write.csv(imputed_data$ximp,"imputed-moneyball-training-data.csv", row.names = FALSE)
```

```{r, include=FALSE, cache=TRUE}
## to ensure similar results we load the imputed data from github 
imputed_data <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/imputed-moneyball-training-data.csv", header = TRUE, check.names = FALSE)
```

## Correlation Matrix 

After competing the imputation, we can implement a correlation matrix to better understand the correlation between variables in the data set. The below matrix is the results and as expected, Number of Wins appears to be most correlated to Base Hits by batters (1B,2B,3B,HR). 

```{r, fig.cap= "Correlation Plot of Training Data Set with imputed values", echo = FALSE, cache=TRUE}
imputed_df_m <- as.matrix(imputed_data)
cor_matrix <- cor(imputed_df_m, use = "everything",  method = c("pearson"))
corrplot(cor_matrix, order = "hclust", addrect = 2, method="square", tl.col = "black", tl.cex = .5, na.label = " ")
```

\newpage

# Data Preparation  

First, we chose to eliminate two variables that had a significant number of missing data points. These variables were Batters hit by pitch (get a free base) and Caught stealing, which were missing `r percent(2085/2276)` and `r percent(772/2276)` respectively. 

```{r, include = FALSE, cache=TRUE}
imputed_df <- imputed_data %>% select(-`Batters hit by pitch (get a free base)`, -`Caught stealing`)
```

Additionally, we reduced the data set to the following variables for modeling simplicity. Base Hits by batters (1B,2B,3B,HR), Strikeouts by batters, Walks by batters, Double plays, Walks allowed, Triples by batters (3B), and Hits allowed. 

Missing values in the remaining columns had been imputed using the random forest method as previous discussed in section 3.1. 

## Outliers 

We chose winsorizing as the method to address outliers. Instead of trimming values, winsorizing uses the interquantile range to replace values that are above or below the interquantile range multiplied by a factor. Those values above or below the range multiplied by the factor are then replaced with max and min value of the interquantile range. Using the factor 2.2 for winsorizing outliers is a method developed my Hoaglin and Iglewicz and published Journal of American Statistical Association in 1987[^2].  

[^2]:Hoaglin, D. C., and Iglewicz, B. (1987), Fine tuning some resistant rules for outlier labeling, Journal of American Statistical Association, 82, 1147-1149.

The below table is the results of the winsorizing of the data. 

```{r, echo=FALSE, include = FALSE}
winsorize <- function(x, multiple=2.2)
              {
                q <- quantile(x)
                iqr <- IQR(x)
                iqrAdjusted <- iqr*multiple
                
                rangeLow <- q['25%'] - iqrAdjusted
                rangeHigh <- q['75%'] + iqrAdjusted
                
                x[x<rangeLow] <- min(x[x > rangeLow])
                x[x>rangeHigh] <- max(x[x < rangeHigh])
                
                return(x)  
}

for (i in 2:length(imputed_df)){
  imputed_df[i] <- sapply(imputed_df[i], function(x) winsorize(x))
} 

imputed_df <- as.data.frame(do.call(cbind, imputed_df))
```

```{r, results='asis', echo=FALSE}
descriptive <- describe(imputed_df, 
                        descript = "Table 2 : Descriptive Statistics after Winsorizing Outliers", digits = digits) 

for (i in seq(1:length(descriptive))){ 
                     for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
                                         }
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
     
     descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[7] <- "Median"
     
     descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[8] <- "SD"
     
     descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[9] <- "Skew"
     
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder 
}

latex(descriptive, file = '')
```

## Box Cox Transformation

```{r, echo=FALSE, cache=TRUE, results = 'asis'}
l1 <- BoxCox.lambda(imputed_df$`Number of wins`)
```

We choose the Box Cox transformation for the following variables to improve linearity in our model. The lambda for the Box Cox transformation of our response variable is `r round(l1,4)` which indicates that we should square the response variable to improve linearity. Also, we discovered that it was not necessary to transform Base Hits by Batters because the significance levels of the variable before and after transformation were the same. 

# Models Built

All models included Base Hits by batters (1B,2B,3B,HR) which is the most correlated variable to Number of Wins as indicated in the correlation matrix. This is expected as Base Hits are necessary to win any game.

## Model 1 
 
We added `Walks by batters` because a batter being walked would put a runner on a base and therefore in a better position to score. Additionally, Strikeouts by batters would be negatively correlated to the Number of Wins because if a batter strikes out they are not able to provide runs which are criticaly to winning. 

```{r, results='asis', echo=FALSE, eval=TRUE, cache=TRUE}
lmfit1 <- lm(data = imputed_df, 
           sqrt(`Number of wins`) ~ `Base Hits by batters (1B,2B,3B,HR)` +  
                                    `Walks by batters` + 
                                    `Strikeouts by batters`)

stargazer(lmfit1, header = FALSE,  
          covariate.labels = c("Base Hits by batters (1B,2B,3B,HR)", 
                               "Walks by batters", 
                               "Strikeouts by batters"),
          dep.var.caption  = c("Model 1"),
          dep.var.labels   = c("$\\sqrt{\\textnormal{Number~of~wins}}$"))
```

The F-statistic is 201.6, and the p-value indicates that this model is significant. Additionally, we see the adjusted R-squared is .2092 but unexpectedly Strikeouts by batters has a positive coefficient and all three predictors are significant.  

The below plot of our fitted values against our residuals indicate that there is Heteroskadistity and showing uneven variation. 

```{r, echo=FALSE}
plot(lmfit1$fitted.values, lmfit1$residuals)
```

## Model 2 

We added Walks allowed and Double Plays. The reason being that Walks allowed is possibly an indicator of poor pitching and Double Plays is an indicator of a competent infield team that prevents other teams from scoring. 

```{r, echo= FALSE, results = 'asis'}
lmfit2 <- lm(data = imputed_df, 
           sqrt(`Number of wins`) ~ `Base Hits by batters (1B,2B,3B,HR)` +  
                                    `Walks allowed` + 
                                    `Double Plays`)

stargazer(lmfit2, header = FALSE,  
          covariate.labels = c("Base Hits by batters (1B,2B,3B,HR)", 
                               "Walks allowed", 
                               "Double Plays"),
          dep.var.caption  = c("Model 2"),
          dep.var.labels   = c("$\\sqrt{\\textnormal{Number~of~wins}}$"))
```

The F-statistic is 141.2, and the p-value indicates that this model is significant. We see the adjusted R-squared is 0.1561, however, it was unexpected that double plays has a negative coeffiecient but it was not a significant predictor. 

The below plot of our fitted values against our residuals indicate that there is Heteroskadistity and showing uneven variation. 

```{r, echo=FALSE}
plot(lmfit2$fitted.values, lmfit2$residuals)
```

## Model 3 

We included Triples by batters and Hits allowed. Additonally, as expected, the Hits allowed has a negative relationship to wins because hits allowed indicates the other team getting a hit and possibly scoring a point. 

```{r, results = 'asis', echo = FALSE}
lmfit3 <- lm(data = imputed_df,
            `Number of wins` ~ `Base Hits by batters (1B,2B,3B,HR)` + 
                               `Triples by batters (3B)` + 
                               `Hits allowed`)

stargazer(lmfit3, header = FALSE,  
          covariate.labels = c("Base Hits by batters (1B,2B,3B,HR)", 
                               "Triples by batters (3B)", 
                               "Hits allowed"),
          dep.var.caption  = c("Model 3"),
          dep.var.labels   = c("$\\sqrt{\\textnormal{Number~of~wins}}$"))
```

The F-statistic is 157.5 and based on our p-values this model is significant. The Adjusted R-squared is 0.1711. However, the Triples by batters (3B) is less significant due to the colinearity with Base Hits by batters (1B, 2B,3B, HR). 

The below plot of our fitted values against our residuals indicate that there is Heteroskadistity and showing uneven variation. 

```{r, echo=FALSE}
plot( lmfit3$fitted.values, lmfit3$residuals)
```

\newpage

# Selected Model 

```{r, eval=TRUE, echo=FALSE, message=FALSE}
eval_data <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/moneyball-evaluation-data.csv")

colnames(eval_data) <- mapvalues(as.vector(colnames(eval_data)), 
                            from = str_trim(data_dictionary$VARIABLE.NAME..), 
                            to = as.vector(str_trim(data_dictionary$DEFINITION)))
eval_data <- eval_data %>%
             mutate(`Sqrt of Strikeouts by batters` =  sqrt(`Strikeouts by batters`))
```

Our residuals in each model indcated Heteroskadistity and showed uneven variation. Therefore, we chose the model with the highest Adjusted R-squared which was Model 1. The Adjusted R-squared of each model is provided in the below table. 

```{r, eval = TRUE, echo=FALSE, results = 'asis'}
options(xtable.comment = FALSE)

model1 <- c(1, 0.209, 201.646, 'Significant', 'Not good', 'shows curve', 'yes')
model2 <- c(2, 0.156, 141.228, 'Significant', 'Not good', 'shows curve', 'yes')
model3 <- c(3, 0.171, 157.533, 'Significant', 'Not good', 'shows curve', 'yes')
models <- t(rbind(model1, model2) %>% rbind(model3)) %>% data.frame()
rownames(models) <- c("Model", "Adjusted R Squared", "F-statistic", "P Value for F-Statistic", "Residual vs Fitted Constant Variation" , "Residual vs Fitted Curve","Residual vs Fitted Curve Heteroscedasticity")
colnames(models) <- NULL

xtable(models, align = c("l", "c", "c", "c"))

```

```{r, echo=FALSE}
options(scipen=999)
fmodel <- c(lmfit1$coefficients[[1]], 
            lmfit1$coefficients[[2]], 
            lmfit1$coefficients[[3]], 
            lmfit1$coefficients[[4]])
```

Therefore, our final model with the greatest Adjusted R-squared is: 

$$
\begin{aligned}
  \sqrt{\textnormal{Number~of~wins}}~=~&\textnormal{`r round(fmodel[2],6)` * Base Hits by batters (1B,2B,3B,HR)} \\ 
                                       &\textnormal{+ `r round(fmodel[3],6)` * Walks by batters} \\
                                       &\textnormal{+ `r round(fmodel[4],8)` * Strikeouts by batters} \\
                                       &\textnormal{+ `r round(fmodel[1],6)`}
\end{aligned}
$$

Additionally, we are 95% confident that our regression values lie between the two values from the output in the below table.

```{r, echo=FALSE, results='asis'}
options(scipen=0)
xtable(confint(lmfit1,conf.level=0.95))
```

# Prediction on Evaluation Data

Using our best performing model we used the `predict` function and excluded evaluation data with missing values. The below table is our prediction results for the evaluation data set. 

```{r, eval = TRUE, echo = FALSE, results = 'asis'}
for (i in 2:length(eval_data)){  
  eval_data[i] <- sapply(eval_data[i], function(x) as.numeric(x))
} 

eval_data <- as.data.frame(do.call(cbind, eval_data))
eval_data$predictions <- predict(lmfit1, eval_data)

eval_data <- eval_data %>%
             mutate(predictions = as.integer(predictions^2))

eval_results <- eval_data %>%
                filter(!is.na(predictions)) %>%
                select(`Identification Variable (do not use)`, predictions)

kable(eval_results)
```

\newpage

# Appendix A

## Session Info

```{r, results='asis', echo=FALSE, eval = TRUE}
toLatex(sessionInfo())
```

## Citations

```{r, results='asis', echo=FALSE, eval = TRUE}
x <- citation("Hmisc")
toBibtex(x)

#Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr, 
#stringr, e1071, corrplot, knitcitations, bibtex, missForest,
#foreach, doParallel, stargazer, forecast
```

## Data Dictionary

```{r, results='asis', echo=FALSE, cache=TRUE}
kable(data_dictionary)
```

## R source code

#TODO updated file name when done, check homework requirements for filename - Christophe 
Please see attached XXXXX.rmd file




