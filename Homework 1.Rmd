---
title: "Homework 1"
author: "Group 1"
date: ''
output:
  pdf_document:
    includes:
      in_header: header.tex
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
---

\begin{center}
\bigskip
\bigskip
\bigskip
Prepared for:\\
\medskip
Dr. Nathan Bastian\\
\smallskip
City University of New York - Data 621\\
\bigskip
Prepared by:\\
\medskip
Group 1\\ 
\medskip
Senthil Dhanapal\\ 
\smallskip
Yadu Chittampalli\\
\smallskip
Christophe Hunt\\  

\end{center}

```{r, include = FALSE}
library(pacman)
p_load(Hmisc, xlsx, knitr, scales, magrittr, tidyr, plyr, dplyr, 
       stringr, e1071, corrplot, knitcitations, bibtex, missForest,
       foreach, doParallel, stargazer)
```

```{r, include=FALSE, cache=TRUE}
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", 
              destfile = "Data Dictionary HW1 - Group 1.xlsx", mode='wb')
data_dictionary <- read.xlsx("Data Dictionary HW1 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW1 - Group 1", full.names = TRUE))
```
\newpage


# Introduction

The ability to analyize and predict performance of a professional baseball team using many dimensions is critical to competitive success for our organization. Therefore, we have analyzed the records of numerous professional baseball team from the years 1871 to 2006. Our hope is that the following report and the resulting predictive models will better inform the organization and assist in making data driven decisions moving forward. 

"The goal of a baseball team is to win more games than any other team. Since one team has very little control over the number of games other teams win, the goal is essentially to win as many games as possible. Therefore, it is of interest to measure the player's contribution to the team's wins." Grabiner, B. D. [^1] While we do not have the variables at the player's individual contribution level, we do have the entire teams contributions as an aggregate and will analyze that information. 

[^1]: (Grabiner, B. D. (n.d.). [The Sabermetric Manifesto.](http://seanlahman.com/baseball-archive/sabermetrics/sabermetric-manifesto/) Retrieved September 10, 2016 from http://seanlahman.com/baseball-archive/sabermetrics/sabermetric-manifesto/) 

# Statement of the Problem

The purpose of this report is to determine the batting, baserun, pitching, and fielding effects on a baseball team's ability to win.  

# Data Exploration  

Note that each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season. The following Table 1 - Descriptive Statistics provides the detailed descriptive statistics regarding our variable of interest - Number of Wins and our possible explanatory variables. 

We noted that several variables were missing a nontrivial amount of observations and these variables are Strikeouts by batters, Stolen Bases, Caught stealing, Batters hit by pitch (get a free base), Strikeouts by pitcher, and Double plays. So we will need to address the missing values for further analysis. 


```{r, echo=FALSE, results='asis'}
df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/moneyball-training-data.csv")

colnames(df) <- mapvalues(as.vector(colnames(df)), 
                            from = str_trim(data_dictionary$VARIABLE.NAME..), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1) 

descriptive <- describe(df %>% select(-`Identification Variable (do not use)`), 
                        descript = "Table 1 : Descriptive Statistics", digits = digits) 

for (i in seq(1:length(descriptive))){
                     for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
                                         }
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
     
     descriptive[[i]]$counts[7] <- round(sapply(df[i+1], function(x) median(x, na.rm=TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[7] <- "Median"
     
     descriptive[[i]]$counts[8] <- round(sapply(df[i+1], function(x) sd(x, na.rm=TRUE)), digits = digits)
     names(descriptive[[i]]$counts)[8] <- "SD"
     
     descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:8,5:6)]) #reorder 
}

latex(descriptive, file = '')
```

## Imputing Missing Values  

In order to address the missing values in our variables we used a nonparametric imputation method (Random Forest) to impute missing values. We chose a nonparametric method due to several variables having significant skew and greater than expected kurtosis values.  

```{r, results='asis', echo = FALSE, include=FALSE, cache=TRUE, eval=FALSE}
registerDoParallel(cl = makeCluster(2), cores = 3)

set.seed(1234)

imputed_data <- df %>% 
              select(-`Identification Variable (do not use)`) %>%
              missForest(maxiter = 10, ntree = 100, parallelize = 'forests')

write.csv(imputed_data$ximp,"imputed-moneyball-training-data.csv", row.names = FALSE)
```

```{r, include=FALSE}
## to ensure similar results we load the imputed data from github 
imputed_data <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/imputed-moneyball-training-data.csv", header = TRUE, check.names = FALSE)
```

## Correlation Matrix 

After competing the imputation, we can implement a correlation matrix to better understand the correlation between variables in the data set. The below matrix is the results and interestingly, Number of Wins appears to be most correlated to Base Hits by batters (1B,2B,3B,HR). 

```{r, fig.cap= "Correlation Plot of Training Data Set with imputed values", echo = FALSE}
imputed_df_m <- as.matrix(imputed_data)
cor_matrix <- cor(imputed_df_m, use = "everything",  method = c("pearson"))
corrplot(cor_matrix, order = "hclust", addrect = 2, method="square", tl.col = "black", tl.cex = .5, na.label = " ")
```

\newpage

# Data Preparation  

First, we chose to eliminate two variables that had a significant number of missing data points. These variables were Batters hit by pitch (get a free base) and Caught stealing, which were missing `r percent(2085/2276)` and `r percent(772/2276)` respectively. 

```{r, include = FALSE}
imputed_df <- imputed_data %>% select(-`Batters hit by pitch (get a free base)`, -`Caught stealing`)
```

Missing values in the remaining columns had been imputed using the random forest method as previous discussed in section 3.1. 

`The rows containing all of the outliers were removed from the original dataset to reduce the skewness. After all of these rows were removed, the skew in the number of walks allowed was significantly reduced to below 1. `

The Box-Cox transformation was done on the number of base hits by batters. As a result of this transformation, the skew in the number of base hits by batters was significantly reduced to below 1.

# Models Built

```{r}
lmfit <- lm(data = imputed_df, 
           `Number of wins` ~ `Base Hits by batters (1B,2B,3B,HR)` + `Homeruns by batters (4B)` +  sqrt(`Strikeouts by batters`))
summary(lmfit)
layout(matrix(c(1,2,3,4),2,2))
plot(lmfit)
```

Using the training data set, build at least three different multiple linear regression models, using different variables
(or the same variables with different transformations). Since we have not yet covered automated variable
selection methods, you should select the variables manually (unless you previously learned Forward or Stepwise
selection, etc.). Since you manually selected a variable for inclusion into the model or exclusion into the model,
indicate why this was done.
Discuss the coefficients in the models, do they make sense? For example, if a team hits a lot of Home Runs, it
would be reasonably expected that such a team would win more games. However, if the coefficient is negative
(suggesting that the team would lose more games), then that needs to be discussed. Are you keeping the model
even though it is counter intuitive? Why? The boss needs to know.

\newpage

# Selected Model 
Decide on the criteria for selecting the best multiple linear regression model. Will you select a model with slightly
worse performance if it makes more sense or is more parsimonious? Discuss why you selected your model.
For the multiple linear regression model, will you use a metric such as Adjusted R2
, RMSE, etc.? Be sure to
explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other
relevant model output. Using the training data set, evaluate the multiple linear regression model based on (a)
mean squared error, (b) R2
, (c) F-statistic, and (d) residual plots. Make predictions using the evaluation data set.

```{r, echo=FALSE, results='asis'}
stargazer::stargazer(lmfit)
```

# Appendix A

## Session Info

```{r, results='asis', echo=FALSE}
toLatex(sessionInfo())
```

## Citations

## Data Dictionary

```{r, results='asis', echo=FALSE, cache=TRUE}
kable(data_dictionary)
```

## R source code
