View(df)
getwd()
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
View(data_dictionary)
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-evaluation-data.csv"))
View(df)
View(data_dictionary)
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
colnames(df) <- mapvalues(as.vector(colnames(df)),
from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
View(data_dictionary)
View(df)
View(df)
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
colnames(df) <- mapvalues(as.vector(colnames(df)),
from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
View(df)
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
descriptive
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
descriptive
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
```
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
latex(descriptive, file = '')
descriptive
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df %>% select(-rad) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
View(df)
df %>% mutate_each(funs, as.numeric)
df %>% mutate_each(funs, as.numeric())
?mutate_each
df %>% mutate_each(funs, numeric)
?mutate_each
df %>% mutate_each(as.numeric())
df %>% mutate_each(funs(as.numeric())
)
mutate_each(funs(as.numeric))
df %>% mutate_each(funs(as.numeric))
descriptive <- describe(df %>% mutate_each(funs(as.numeric)) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
descriptive <- describe(df %>% mutate_each(funs(as.numeric)) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
attr(descriptive)
unlist(descriptive)
test <- df %>% mutate_each(funs(as.numeric))
descriptive <- describe( test# TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
test <- df %>% mutate_each(funs(as.character()))
test <- df %>% mutate_each(funs(as.character)
)
descriptive <- describe( test# TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
df_m <- as.matrix(df)
cor_matrix <- cor(df_m, use = "everything",  method = c("pearson"))
corrplot(cor_matrix, order = "hclust", addrect = 2, method="square", tl.col = "black", tl.cex = .5, na.label = " ")
x <- regsubsets(target ~ ., data = dfTr, nbest = 1)
summary(x)
# Chunk 2
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyverse,
stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc,
foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps)
# Chunk 3
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/raw/master/Homework%203/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW3 - Group 1.xlsx", mode = 'wb')
daDict <- read.xlsx("Data Dictionary HW3 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW3 - Group 1", full.names = TRUE))
# Chunk 4
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)  %>%
select(`Variable Abbreviation`, `Variable Definition` ),
align = c("c","l"))
# Chunk 5
library(matrixStats)
crimes <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%203/crime-training-data.csv")
abs(skewness(crimes))
data.frame(cbind(variables = colnames(crimes), sd = colSds(as.matrix(crimes))))
# Chunk 6
dfTr <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%203/crime-training-data.csv")
#colnames(dfTr) <- mapvalues(as.vector(colnames(dfTr)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe( dfTr %>% select(-target) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
latex(descriptive, file = '')
# Chunk 7
dfTrMx <- as.matrix(dfTr)
corMx <- cor(dfTrMx , use = "everything",  method = c("pearson"))
corrplot(corMx, order = "hclust", addrect = 2, method = "square", tl.col = "black", tl.cex = .5, na.label = " ")
# Chunk 8
winsorize <- function(x, multiple=2.2)
{
q <- quantile(x)
iqr <- IQR(x)
iqrAdjusted <- iqr*multiple
rangeLow <- q['25%']-iqrAdjusted
rangeHigh <- q['75%']+iqrAdjusted
x[x<rangeLow] <- min(x[x>rangeLow])
x[x>rangeHigh] <- max(x[x<rangeHigh])
return(x)
}
# Chunk 9
library(forecast)
winsorizedandtransformed <- function(dataset){
dataset <- dataset[,1:ncol(dataset)]
wdataset <- tdataset <- matrix(data = 0, nrow = nrow(dataset), ncol = ncol(dataset))
l1 <- numeric(ncol(dataset))
for (i in 1:length(l1)){
if(i == 3 || i == length(l1)){
wdataset[,i] <- dataset[,i]
tdataset[,i] <- wdataset[,i]
}
else {
wdataset[,i] <- winsorize(dataset[,i], multiple = 2.2)
l1[i] <- BoxCox.lambda(wdataset[,i])
tdataset[,i] <- BoxCox(wdataset[,i],l1[i])
}
colnames(tdataset) <- colnames(dataset)
}
return(data.frame(tdataset))
}
wtCrimes <- winsorizedandtransformed(crimes)
stargazer(wtCrimes, header = FALSE)
# Chunk 10
fullModel <- lm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat + medv, data = na.omit(wtCrimes))
fit <- glm(step(fullModel, direction = "backward", trace = F))
summary(fit)
plot(subsetModel)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 1)
plot(subsetModel)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 5)
plot(subsetModel)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 1)
plot(subsetModel)
glm(target~.,family=binomial(link='logit'),data=train)
glm(target~.,family=binomial(link='logit'),data=dfTr)
glm(target~.,family=binomial,data=dfTr)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 1)
summary(subsetModel)
summary(subsetModel[8])
subsetModel[8]
subsetModel[9]
subsetModel[12]
subsetModel[28]
subsetModel$nbest
subsetModel$force.in
summary(subsetModel, matrix.logical=TRUE)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 1)
summary(subsetModel, matrix.logical=TRUE)
plot(subsetModel)
glm(target~ nox + age + rad tax + ptratio + black + lstat + medv,family=binomial,data=dfTr)
glm(target~nox + age + rad tax + ptratio + black + lstat + medv,family=binomial,data=dfTr)
glm(targe t~ nox + age + rad + tax + ptratio + black + lstat + medv,family=binomial,data=dfTr)
glm(target ~ nox + age + rad + tax + ptratio + black + lstat + medv,family=binomial,data=dfTr)
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)  %>%
select(`Variable Abbreviation`, `Variable Definition` ),
align = c("c","l"))
daDict %>% filter(VARIABLE.TYPE == "Predictor Variable") %>%  mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)  %>% select(`Variable Abbreviation`, `Variable Definition` )
daDict %>% filter(VARIABLE.TYPE == "Predictor Variable") %>%  mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)  %>% select(`Variable Abbreviation`, `Variable Definition`)
daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(`Variable Abbreviation` = VARIABLE.NAME, `Variable Definition` = DEFINITION)  %>%
select("Variable Abbreviation", "Variable Definition" ),
align = c("c","l"))
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
select(Abbreviation, Definition),
align = c("c","l"))
# Chunk 2
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyverse,
stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc,
foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps)
# Chunk 3
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/raw/master/Homework%203/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW3 - Group 1.xlsx", mode = 'wb')
daDict <- read.xlsx("Data Dictionary HW3 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW3 - Group 1", full.names = TRUE))
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
select(Abbreviation, Definition),
align = c("c","l"))
daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
select(Abbreviation, Definition)
x <- daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
select(Abbreviation, Definition)
x <- daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
select_(Abbreviation, Definition)
library(tidyr)
library(plyr)
library(dplyr)
x <- daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
dplyr::select(Abbreviation, Definition)
align = c("c","l"))
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
dplyr::select(Abbreviation, Definition),
align = c("c","l"))
# Chunk 2
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyverse,
stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc,
foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps)
# Chunk 3
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/raw/master/Homework%203/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW3 - Group 1.xlsx", mode = 'wb')
daDict <- read.xlsx("Data Dictionary HW3 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW3 - Group 1", full.names = TRUE))
# Chunk 4
kable(daDict %>%
filter(VARIABLE.TYPE == "Predictor Variable") %>%
mutate(Abbreviation = VARIABLE.NAME, Definition = DEFINITION)  %>%
dplyr::select(Abbreviation, Definition),
align = c("c","l"))
# Chunk 5
library(matrixStats)
crimes <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%203/crime-training-data.csv")
abs(skewness(crimes))
data.frame(cbind(variables = colnames(crimes), sd = colSds(as.matrix(crimes))))
# Chunk 6
dfTr <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%203/crime-training-data.csv")
#colnames(dfTr) <- mapvalues(as.vector(colnames(dfTr)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe( dfTr %>% dplyr::select(-target) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
latex(descriptive, file = '')
# Chunk 7
dfTrMx <- as.matrix(dfTr)
corMx <- cor(dfTrMx , use = "everything",  method = c("pearson"))
corrplot(corMx, order = "hclust", addrect = 2, method = "square", tl.col = "black", tl.cex = .5, na.label = " ")
# Chunk 8
winsorize <- function(x, multiple=2.2)
{
q <- quantile(x)
iqr <- IQR(x)
iqrAdjusted <- iqr*multiple
rangeLow <- q['25%']-iqrAdjusted
rangeHigh <- q['75%']+iqrAdjusted
x[x<rangeLow] <- min(x[x>rangeLow])
x[x>rangeHigh] <- max(x[x<rangeHigh])
return(x)
}
# Chunk 9
library(forecast)
winsorizedandtransformed <- function(dataset){
dataset <- dataset[,1:ncol(dataset)]
wdataset <- tdataset <- matrix(data = 0, nrow = nrow(dataset), ncol = ncol(dataset))
l1 <- numeric(ncol(dataset))
for (i in 1:length(l1)){
if(i == 3 || i == length(l1)){
wdataset[,i] <- dataset[,i]
tdataset[,i] <- wdataset[,i]
}
else {
wdataset[,i] <- winsorize(dataset[,i], multiple = 2.2)
l1[i] <- BoxCox.lambda(wdataset[,i])
tdataset[,i] <- BoxCox(wdataset[,i],l1[i])
}
colnames(tdataset) <- colnames(dataset)
}
return(data.frame(tdataset))
}
wtCrimes <- winsorizedandtransformed(crimes)
stargazer(wtCrimes, header = FALSE)
# Chunk 10
fullModel <- lm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat + medv, data = na.omit(wtCrimes))
fit <- glm(step(fullModel, direction = "backward", trace = F))
summary(fit)
subsetModel <- regsubsets(target ~ ., data = dfTr, nbest = 1)
summary(subsetModel, matrix.logical = TRUE)
subsetModel[8]
summary(subsetModel[9], matrix.logical = TRUE)
summary(subsetModel[19], matrix.logical = TRUE)
subsetModel[19]
subsetModel$xnames[8]
subsetModel$xnames
subsetModel[20]
subsetModel[21]
subsetModel[28]
subsetModel$force.in
subsetModel[22]
subsetModel[23]
subsetModel[24]
summary <- summary(subsetModel)
as.data.frame(summary$outmat)
kable(summary$outmat)
summary(subsetModel)
plot(summary)
subsetModel <- glm(target ~ nox + age + rad + tax + ptratio + black + lstat + medv, family = binomial, data = dfTr)
stargazer(subsetModel)
fullModel <- lm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat + medv, data = na.omit(wtCrimes))
fit <- glm(step(fullModel, direction = "backward", trace = F))
summary(fit)
library(matrixStats)
crimes <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%203/crime-training-data.csv")
abs(skewness(crimes))
kable(t(abs(skewness(crimes))))
kable(as.data.frame(abs(skewness(crimes))))
dfSkew <- as.data.frame(abs(skewness(crimes)))
dfSkew <- as.data.frame(abs(skewness(crimes)))
colnames(dfSkew) <- c("variable", "skew")
kable(dfSkew)
dfSkew <- as.data.frame(abs(skewness(crimes)))
colnames(dfSkew) <- c("variable", "skew")
dfSkew <- as.data.frame(abs(skewness(crimes)))
colnames(dfSkew) <- c("skew")
kable(dfSkew)
dfSkew <-setDT((abs(skewness(crimes))), keep.rownames = TRUE)
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyverse,
stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc,
foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps, data.table)
dfSkew <- setDT((abs(skewness(crimes))), keep.rownames = TRUE)
dfSkew <- setDT(as.data.frame(abs(skewness(crimes))), keep.rownames = TRUE)
dfSkew
setDT(as.data.frame(abs(skewness(crimes))), keep.rownames = TRUE)
dfSkew <- setDT(as.data.frame(abs(skewness(crimes))), keep.rownames = TRUE)[]
dfSkew
colnames(dfSkew) <- c("variables", "skew")
kable(dfSkew)
kable(dfSkew, align = c("l", "c")
kable(dfSkew, align = c("l", "c"))
kable(dfSkew, align = c("l", "c"))
dfTr %>% dplyr::select(-target, -chas, -rad)
install.packages("highlight")
?highlight
library("highlight", lib.loc="~/r/win-library/3.3")
?highlight
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyverse,
stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc,
foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps, data.table, highlight, car)
vif(subsetModel)
kable(vif(fit))
vif(fit)
kable(as.data.frame(vif(fit)))
dfVifFit <- setDT(as.data.frame(vif(fit)), keep.rownames = TRUE)[]
colnames(dfVifFit) <- c("variables", "VIF")
kable(dfVifFit, align = c("l", "c"))
dfVifSubset <- setDT(as.data.frame(vif(subsetModel)), keep.rownames = TRUE)[]
colnames(dfVifSubset) <- c("variables", "VIF")
kable(dfVifSubset, align = c("l", "c"))
