dfForPlot <-  data.frame(rbind(dfForPlot,data.frame(plotCoord)))
}
plot(x=dfForPlot$fpr,y=dfForPlot$tpr,lwd=2, type="l", xlab="FPR", ylab="TPR")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1)
return (dfForPlot)
}
ROC.Coordinates <- function(dfData, classVar, probVar, posVal, negVal, threshold){
pred <- rep(negVal,length(dfData[,1]))
dfNew <- dfData
pred[which(dfData[probVar]>=threshold)]  <- posVal
dfNew$pred <- as.factor(pred)
sensitivity <- Sensitivity(dfData = dfNew, predVar = "pred",actualVar = classVar,posVal = posVal,negVal = negVal)
specificity <- Specificity(dfData = dfNew, predVar = "pred",actualVar = classVar,posVal = posVal,negVal = negVal)
tpr <- sensitivity
fpr <- 1 - specificity
auc <- (sensitivity + specificity)/2
dist <- sqrt((1-tpr)^2 + (fpr)^2)
return(data.frame(threshold,fpr,tpr,auc,dist))
}
calculateAUC <- function(curveInfo){
tpr1 <- 0
fpr1 <- 0
auc <- 0
curveInfo <- curveInfo[order(-curveInfo$threshold),]
for(i in 1:nrow(curveInfo))
{
tpr2 <- curveInfo[i,"tpr"]
fpr2 <- curveInfo[i,"fpr"]
auc <- auc + ((tpr1 + tpr2)/2)*(fpr2-fpr1)
tpr1 <- tpr2
fpr1 <- fpr2
}
return(auc)
}
# Chunk 14
paste0("Accuracy of Predictions = ", percent(Accuracy(scores,'class', 'scored.class', 1, 0)))
# Chunk 15
paste0("Error Rate of Predictions = ", percent(ClassificationErrorRate(scores,'class', 'scored.class', 1, 0)))
# Chunk 16
paste0("Precision of Predictions = ", percent(Precision(scores,'class', 'scored.class', 1, 0)))
# Chunk 17
paste0("Sensitivity of Predictions = ", percent(Sensitivity(scores,'class', 'scored.class', 1, 0)))
# Chunk 18
paste0("Specificity of Predictions = ", percent(Specificity(scores,'class', 'scored.class', 1, 0)))
# Chunk 19
paste0("The F1 Score = ", F1Score(scores,'class', 'scored.class', 1, 0))
# Chunk 20
x <- seq(0,1,0.01)
predVar <- "scored.class"
actualVar <- "class"
posVal <- 1
negVal <- 0
dfData <- scores
classVar <- actualVar
probVar <- "scored.probability"
x <- seq(0,1,0.01)
dfROC <- ROC(dfData,classVar, probVar, posVal, negVal, x)
auc <- calculateAUC(dfROC)
bestValueMethod1 <- dfROC[which(dfROC$dist == min(dfROC$dist)),]
bestValueMethod2 <- dfROC[which(dfROC$auc == max(dfROC$auc)),]
# Chunk 21
x <- seq(0,1,0.001)
dfROC <- ROC(scores, 'class', 'scored.probability', 1 ,  0,  x)
auc <- calculateAUC(dfROC)
bestValueMethod1 <- dfROC[which(dfROC$dist == min(dfROC$dist)),]
bestValueMethod2 <- dfROC[which(dfROC$auc == max(dfROC$auc)),]
# Chunk 22
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
# Chunk 23
paste0("Sensitivity provided by caret pacakge is ",sensitivity(table(scores[,1], scores[,2])))
# Chunk 24
paste0("Specificity provided by caret pacakge is ",specificity(table(scores[,1], scores[,2])))
r (sprintf("{Threshold = %f,fpr = %f,tpr = %f}",
bestPROC[1], bestPROC[2], bestPROC[3]))
(sprintf("{Threshold = %f,fpr = %f,tpr = %f}",
bestPROC[1], bestPROC[2], bestPROC[3]))
# Chunk 1
library(pacman)
p_load(xtable, knitr, pander, xtable, scales, tidyverse, formatR, caret, pROC, Hmisc)
tidy.opts = list(width.cutoff = 60)
# Chunk 2: load in data
classification <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%202/classification-output-data.csv")
# Chunk 3: subset data
scores <- subset(classification, select = c("class", "scored.class", "scored.probability"))
# Chunk 4
m <- table("Actual" = scores$class, "Predicted" = scores$scored.class)
colnames(m) <- c('Predicted Failure', "Predicted Success")
rownames(m) <- c('Actual Failure', 'Actual Success')
kable(m, align = c("c", "c"))
# Chunk 5
colnames(m) <- c('Predicted Failure', "Predicted \nSuccess\n")
rownames(m) <- c('Actual Failure', 'Actual \nSuccess\n')
mosaicplot(t(m), main="Confusion Matrix Plot", xlab = "", ylab = "")
# Chunk 6
TP <- function(dfData, predVar, actualVar, posVal, negVal){
return(length(dfData[which(dfData[predVar]==posVal & dfData[actualVar]==posVal),1]))
}
TN <- function(dfData, predVar, actualVar, posVal, negVal){
return(length(dfData[which(dfData[predVar]==negVal & dfData[actualVar]==negVal),1]))
}
FP <- function(dfData, predVar, actualVar, posVal, negVal){
return(length(dfData[which(dfData[predVar]==posVal & dfData[actualVar]==negVal),1]))
}
FN <- function(dfData, predVar, actualVar, posVal, negVal){
return(length(dfData[which(dfData[predVar]==negVal & dfData[actualVar]==posVal),1]))
}
column_check <- function(df,actual, prediction){
if (sum(colnames(df) %in% c(actual, prediction)) != 2){
return("One or more columns were not found, please verify selections")
}
}
# Chunk 7
Accuracy <- function(dfData, predVar, actualVar, posVal, negVal){
column_check(dfData, predVar, actualVar)
tp <- TP(dfData,predVar,actualVar,posVal,negVal)
tn <- TN(dfData,predVar,actualVar,posVal,negVal)
fp <- FP(dfData,predVar,actualVar,posVal,negVal)
fn <- FN(dfData,predVar,actualVar,posVal,negVal)
return ((tp + tn)/(tp + fp + tn + fn))
}
# Chunk 8
ClassificationErrorRate <- function(dfData, predVar, actualVar, posVal, negVal){
column_check(dfData, predVar, actualVar)
tp <- TP(dfData,predVar,actualVar,posVal,negVal)
tn <- TN(dfData,predVar,actualVar,posVal,negVal)
fp <- FP(dfData,predVar,actualVar,posVal,negVal)
fn <- FN(dfData,predVar,actualVar,posVal,negVal)
return((fp + fn)/(tp + fp + tn + fn))
}
# Chunk 9
Precision <- function(dfData, predVar, actualVar, posVal, negVal){
column_check(dfData, predVar, actualVar)
tp <- TP(dfData,predVar,actualVar,posVal,negVal)
fp <- FP(dfData,predVar,actualVar,posVal,negVal)
return(tp/(tp + fp))
}
# Chunk 10
Sensitivity <- function(dfData, predVar, actualVar, posVal, negVal){
column_check(dfData, predVar, actualVar)
tp <- TP(dfData,predVar,actualVar,posVal,negVal)
fn <- FN(dfData,predVar,actualVar,posVal,negVal)
return(tp/(tp + fn))
}
# Chunk 11
Specificity <- function(dfData, predVar, actualVar, posVal, negVal){
column_check(dfData, predVar, actualVar)
tn <- TN(dfData,predVar,actualVar,posVal,negVal)
fp <- FP(dfData,predVar,actualVar,posVal,negVal)
return(tn/(tn + fp))
}
# Chunk 12
F1Score <- function(dfData, predVar, actualVar, posVal, negVal){
precision <- Precision(dfData,predVar,actualVar,posVal,negVal)
sensitivity <- Sensitivity(dfData,predVar,actualVar,posVal,negVal)
return ((2 * precision * sensitivity)/(precision + sensitivity))
}
# Chunk 13
ROC <- function(dfData, classVar, probVar, posVal, negVal, thresholds){
x <- thresholds
dfForPlot <- data.frame(threshold=integer(), fpr=double(),tpr=double(), auc=double(), dist=double())
for(i in x)
{
plotCoord <- ROC.Coordinates(dfData,classVar, probVar, posVal, negVal, i)
#print(plotCoord)
dfForPlot <-  data.frame(rbind(dfForPlot,data.frame(plotCoord)))
}
plot(x=dfForPlot$fpr,y=dfForPlot$tpr,lwd=2, type="l", xlab="FPR", ylab="TPR")
lines(x=c(0, 1), y=c(0, 1), col="black", lwd=1)
return (dfForPlot)
}
ROC.Coordinates <- function(dfData, classVar, probVar, posVal, negVal, threshold){
pred <- rep(negVal,length(dfData[,1]))
dfNew <- dfData
pred[which(dfData[probVar]>=threshold)]  <- posVal
dfNew$pred <- as.factor(pred)
sensitivity <- Sensitivity(dfData = dfNew, predVar = "pred",actualVar = classVar,posVal = posVal,negVal = negVal)
specificity <- Specificity(dfData = dfNew, predVar = "pred",actualVar = classVar,posVal = posVal,negVal = negVal)
tpr <- sensitivity
fpr <- 1 - specificity
auc <- (sensitivity + specificity)/2
dist <- sqrt((1-tpr)^2 + (fpr)^2)
return(data.frame(threshold,fpr,tpr,auc,dist))
}
calculateAUC <- function(curveInfo){
tpr1 <- 0
fpr1 <- 0
auc <- 0
curveInfo <- curveInfo[order(-curveInfo$threshold),]
for(i in 1:nrow(curveInfo))
{
tpr2 <- curveInfo[i,"tpr"]
fpr2 <- curveInfo[i,"fpr"]
auc <- auc + ((tpr1 + tpr2)/2)*(fpr2-fpr1)
tpr1 <- tpr2
fpr1 <- fpr2
}
return(auc)
}
# Chunk 14
paste0("Accuracy of Predictions = ", percent(Accuracy(scores,'class', 'scored.class', 1, 0)))
# Chunk 15
paste0("Error Rate of Predictions = ", percent(ClassificationErrorRate(scores,'class', 'scored.class', 1, 0)))
# Chunk 16
paste0("Precision of Predictions = ", percent(Precision(scores,'class', 'scored.class', 1, 0)))
# Chunk 17
paste0("Sensitivity of Predictions = ", percent(Sensitivity(scores,'class', 'scored.class', 1, 0)))
# Chunk 18
paste0("Specificity of Predictions = ", percent(Specificity(scores,'class', 'scored.class', 1, 0)))
# Chunk 19
paste0("The F1 Score = ", F1Score(scores,'class', 'scored.class', 1, 0))
# Chunk 20
x <- seq(0,1,0.01)
predVar <- "scored.class"
actualVar <- "class"
posVal <- 1
negVal <- 0
dfData <- scores
classVar <- actualVar
probVar <- "scored.probability"
x <- seq(0,1,0.01)
dfROC <- ROC(dfData,classVar, probVar, posVal, negVal, x)
auc <- calculateAUC(dfROC)
bestValueMethod1 <- dfROC[which(dfROC$dist == min(dfROC$dist)),]
bestValueMethod2 <- dfROC[which(dfROC$auc == max(dfROC$auc)),]
# Chunk 21
x <- seq(0,1,0.001)
dfROC <- ROC(scores, 'class', 'scored.probability', 1 ,  0,  x)
auc <- calculateAUC(dfROC)
bestValueMethod1 <- dfROC[which(dfROC$dist == min(dfROC$dist)),]
bestValueMethod2 <- dfROC[which(dfROC$auc == max(dfROC$auc)),]
# Chunk 22
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
# Chunk 23
paste0("Sensitivity provided by caret pacakge is ",sensitivity(table(scores[,1], scores[,2])))
# Chunk 24
paste0("Specificity provided by caret pacakge is ",specificity(table(scores[,1], scores[,2])))
(sprintf("{Threshold = %f,fpr = %f,tpr = %f}",
bestPROC[1], bestPROC[2], bestPROC[3]))
bestPROC <- coords(roc_curve, "best", ret=c("threshold", "1-specificity", "sensitivity"))
library(pROC)
roc_curve <- roc(dfData$class, dfData$scored.probability)
plot(roc_curve)
bestPROC <- coords(roc_curve, "best", ret=c("threshold", "1-specificity", "sensitivity"))
(sprintf("{Threshold = %f,fpr = %f,tpr = %f}",
bestPROC[1], bestPROC[2], bestPROC[3]))
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
#cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
Matrix
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
library(pROC)
roc_curve <- roc(dfData$class, dfData$scored.probability)
plot(roc_curve)
bestPROC <- coords(roc_curve, "best", ret=c("threshold", "1-specificity", "sensitivity"))
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
library(caret)
library(Hmisc)
`Matrix` <- as.matrix(confusionMatrix(scores[,1], scores[,2]))
cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n')
gsub("!tbp", "h",cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n'))
gsub("\!tbp", "h",cat(capture.output(latex(`Matrix`, file=''))[-1], sep='\n'))
cat(capture.output(gsub("!tbp", "h",latex(`Matrix`, file='')))[-1], sep='\n'))
cat(capture.output(gsub("!tbp", "h",latex(`Matrix`, file=''))[-1], sep='\n'))
gsub("!tbp", "h", latex(`Matrix`, file=''))
gsub("[!tbp]", "h", latex(`Matrix`, file=''))
library(xtable)
library(pandoc)
pandoc.table.return(`Matrix`)
xtable(`Matrix`)
cat(
capture.output(
gsub("[!tbp]", "h", latex(`Matrix`, file=''))
)[-1], sep='\n')
ClassificationErrorRate(scores,'class', 'scored.class', 1, 0) + Accuracy(scores,'class', 'scored.class', 1, 0) == 1
ClassificationErrorRate(scores,'class', 'scored.class', 1, 0) + Accuracy(scores,'class', 'scored.class', 1, 0)
library(faraway)
library(Hmisc)
mdl <- glm(cbind(disease, nondisease) ~ sex+food, family=binomial, babyfood)
install.packages(c("BDgraph", "binseqtest", "BoSSA", "cluster", "colorspace", "Compositional", "daewr", "dti", "evaluate", "extraDistr", "forecast", "future", "ggseas", "infuser", "irtoys", "lokern", "matrixStats", "mc2d", "MCMCglmm", "mixAK", "multiplex", "mvnfast", "pbdBASE", "pcaPP", "postGIStools", "RandomFields", "RandomFieldsUtils", "rbokeh", "reldist", "Rfast", "rstpm2", "seqmon", "Sim.DiffProc", "SIS", "spatialsegregation", "spatstat", "spBayesSurv"))
x <- seq(-2,8,0.2)
pl <- ilogit(modl$coef[1]+modl$coef[2]*x)
pp <- pnorm(modp$coef[1]+modp$coef[2]*x)
pc <- 1-exp(-exp((modc$coef[1]+modc$coef[2]*x)))
plot(x,pl,type="1",ylab="Probability",xlab="Dose") > lines(x,pp,lty=2) > lines(x,pc,lty=5)
data (bliss)
data(bliss)
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-evaluation-data.csv"))
View(df)
getwd()
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
View(data_dictionary)
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-evaluation-data.csv"))
View(df)
View(data_dictionary)
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
colnames(df) <- mapvalues(as.vector(colnames(df)),
from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
View(data_dictionary)
View(df)
View(df)
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
colnames(df) <- mapvalues(as.vector(colnames(df)),
from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
View(df)
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
descriptive
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
descriptive
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
```
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
descriptive <- describe(df, descript = "Table 1 : Descriptive Statistics", digits = digits)
latex(descriptive, file = '')
descriptive
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
#TODO - Get this working when I have internet access
#df <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/Homework 3/crime-evaluation-data.csv")
df <- read.csv(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3","crime-training-data.csv"))
#colnames(df) <- mapvalues(as.vector(colnames(df)), from = str_trim(data_dictionary$VARIABLE.NAME), to = as.vector(str_trim(data_dictionary$DEFINITION)))
digits <- c(1)
descriptive <- describe(df %>% select(-rad) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
# Chunk 1
library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, tidyr, plyr, dplyr,
stringr, e1071, corrplot, knitcitations, bibtex, missForest,
foreach, doParallel, stargazer, forecast)
# Chunk 2
#TODO - Get working when I have internet access
#download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW1 - Group 1.xlsx", mode = 'wb')
setwd(file.path("C:","Users", "Christophe","Documents", "Github", "Data 621 - Group 1", "Homework 3"))
data_dictionary <- read.xlsx("Data Dictionary.xlsx", sheetIndex = 1)
#TODO - update when I get internet access file.remove(dir(getwd(), pattern = "Data Dictionary", full.names = TRUE))
View(df)
df %>% mutate_each(funs, as.numeric)
df %>% mutate_each(funs, as.numeric())
?mutate_each
df %>% mutate_each(funs, numeric)
?mutate_each
df %>% mutate_each(as.numeric())
df %>% mutate_each(funs(as.numeric())
)
mutate_each(funs(as.numeric))
df %>% mutate_each(funs(as.numeric))
descriptive <- describe(df %>% mutate_each(funs(as.numeric)) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
descriptive <- describe(df %>% mutate_each(funs(as.numeric)) # TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
attr(descriptive)
unlist(descriptive)
test <- df %>% mutate_each(funs(as.numeric))
descriptive <- describe( test# TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
test <- df %>% mutate_each(funs(as.character()))
test <- df %>% mutate_each(funs(as.character)
)
descriptive <- describe( test# TODO figure out why rad has a wierd frequency table
, descript = "Table 1 : Descriptive Statistics", digits = digits)
for (i in seq(1:length(descriptive))){
for (j in c(6,9,12)){names(descriptive[[i]]$counts)[j] <- paste0(names(descriptive[[i]]$counts)[j]," freq")
}
descriptive[[i]]$counts <- (descriptive[[i]]$counts[-c(4,7,8:10,11)])
descriptive[[i]]$counts[7] <- round(sapply(df[i + 1], function(x) median(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[7] <- "Median"
descriptive[[i]]$counts[8] <- round(sapply(df[i + 1], function(x) sd(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[8] <- "SD"
descriptive[[i]]$counts[9] <- round(sapply(df[i + 1], function(x) skewness(x, na.rm = TRUE)), digits = digits)
names(descriptive[[i]]$counts)[9] <- "Skew"
descriptive[[i]]$counts <- (descriptive[[i]]$counts[c(1:4,7:9,5:6)]) #reorder
}
latex(descriptive, file = '')
df_m <- as.matrix(df)
cor_matrix <- cor(df_m, use = "everything",  method = c("pearson"))
corrplot(cor_matrix, order = "hclust", addrect = 2, method="square", tl.col = "black", tl.cex = .5, na.label = " ")
