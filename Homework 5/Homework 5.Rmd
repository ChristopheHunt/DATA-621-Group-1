---
title: "Homework 5"
author: "Group 1"
date: ''
output:
  pdf_document:
    includes:
      in_header: header.tex
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
---

```{r programming style guide, echo=FALSE, eval=FALSE}
##Style guide
##USE CAMEL CASING!! https://en.wikipedia.org/wiki/Camel_case, start with lowercase then each word after start with upper case
##upper case for vector, lists, etc. ex. X <- c("yes","no","true","false")
##lower case for scalar/single value, ex. x <- 1
##data frame start with df followed by description, ex. dfEval <- evaluation data frame
##assignments use "<-" not "="
```

```{r options and library load, include = FALSE, cache=TRUE}
options(xtable.comment = FALSE)

library(pacman)
p_load(Hmisc, xlsx, xtable, knitr, scales, magrittr, magrittr, tidyverse, stringr, e1071, corrplot, knitcitations, bibtex, missForest, abc, foreach, doParallel, stargazer, forecast, matrixStats, glmulti, leaps, data.table, highlight, car, pracma, boot, pander, ggplot2, lars, MASS)
```

\begin{center}
\bigskip
\bigskip
\bigskip
Prepared for:\\
\medskip
Dr. Nathan Bastian\\
\smallskip
City University of New York, School of Professional Studies - Data 621\\
\bigskip
Prepared by:\\
\medskip
Group 1\\ 
\medskip
Senthil Dhanapal\\ 
\smallskip
Yadu Chittampalli\\
\smallskip
Christophe Hunt\\  

\end{center}

\newpage

# Introduction

The wine industry was valued at \$257.5 billion in 2012 and is predicted to be valued at \$303.6 billion by 2016.[^1] As wine is a consumer product, accommodating consumer preference is critical to maintaining a competitive advantage. By understanding the factors involved in wine sales we can better understand consumer behavior and adjust our strategies accordingly. 


[^1]: "Research and Markets: Wine: 2012 Global Industry Almanac - The Global Wine Market Grew by 3.1% in 2011 to Reach a Value of \$257.5 Billion." Research and Markets: Wine: 2012 Global Industry Almanac - The Global Wine Market Grew by 3.1% in 2011 to Reach a Value of $257.5 Billion | Business Wire. N.p., 21 May 2012. Web. 20 Nov. 2016.

# Statement of the Problem

The purpose of this report is to develop statistical models to make inference into the factors associated with the number of cases of wine sold.

# Data Exploration  

## Variables Explained

The variables provided in the `Wine Training Data Set` are explained below:

```{r data dictionary load, include=FALSE, cache=TRUE}
download.file("https://github.com/ChristopheHunt/DATA-621-Group-1/raw/master/Homework%205/Data%20Dictionary.xlsx?raw=true", destfile = "Data Dictionary HW5 - Group 1.xlsx", mode = 'wb')
daDict <- read.xlsx("Data Dictionary HW5 - Group 1.xlsx", sheetIndex = 1)
file.remove(dir(getwd(), pattern = "Data Dictionary HW5 - Group 1", full.names = TRUE))
```

```{r data dictionary table, eval=TRUE, results='asis', echo=FALSE, cache=TRUE}
pandoc.table(daDict %>% 
      mutate(`Variable Code` = VARIABLE.NAME, Definition = DEFINITION)  %>%
      dplyr::select(`Variable Code`, Definition),
      justify = c("center","left"), emphasize.strong.rows = seq(from = 1, to = nrow(daDict), by = 2),
      table.alignment.rownames = 'centre',style="multiline")
```


```{r data prep, echo=FALSE, results='asis', cache=TRUE}
dfTr <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%205/wine-training-data.csv") %>%
        dplyr::select(-dplyr::contains("INDEX")) %>%
        map_if(is.integer, as.numeric) %>%
        as.data.frame() %>%
        mutate(LabelAppeal = factor(LabelAppeal, levels = c(-2, -1, 0, 1, 2)),
               STARS = factor(STARS, levels = c(1,2,3,4)),
               TARGET = as.integer(TARGET)) 
```

\newpage

## Variables Summary Statistics

### Discrete Variables

Interestingly, we can see some general sense of the make up of our data set. In this set, most wines sell between 3 and 5 cases, have no label appeal, and very few received 4 stars. 

```{r nominal variables, echo=FALSE, results='asis', cache=TRUE}
options(xtable.comment = FALSE)

reporttools::tableNominal(dfTr %>% dplyr::select(TARGET, LabelAppeal, STARS), 
                        cap = "Wine Training Data Table of Discrete Variables", 
                        lab = "tab: nominal", 
                        print.pval = "fisher",
                        caption.placement = "top", longtable = TRUE, 
                        add.to.row = list(pos = list(0), command = "\\hline \\endhead "))
```


### Continous Variables

We see that Density is a very narrow measurement, the minimum value is 0.9 and the maximum is 1.1. 

```{r continous variables, echo=FALSE, results='asis', cache=TRUE}
options(xtable.comment = FALSE)
reporttools::tableContinuous(dfTr %>% dplyr::select(-TARGET, -LabelAppeal, -STARS) , 
                             longtable = TRUE, 
                             cap = "Wine Training Data Table of Continuous Variables",
                             caption.placement = "top")
```

\newpage

## Imputting Missing Values

In order to address the missing values in our variables we used a non-parametric imputation method (Random Forest) using the `missForest` package. The function is particularly useful in that it can handle any type of input data and it will make as few assumptions about the structure of the data as possible.[^3]

[^3]: Stekhoven, Daniel J., and Peter B?hlmann. ["MissForest-non-parametric missing value imputation for mixed-type data." Bioinformatics 28.1 (2012): 112-118](http://bioinformatics.oxfordjournals.org/content/28/1/112.short).

```{r missForest imputation of data, results='asis', echo = FALSE, include=FALSE, cache=TRUE, eval=FALSE}
registerDoParallel(cl = makeCluster(10), cores = 2)

set.seed(1234)

imputed_data <- dfTr %>% missForest(maxiter = 10, ntree = 100, replace = TRUE, parallelize = 'forests', verbose = TRUE) #Takes approximately 30 minutes to process, resource intensive

write.csv(imputed_data$ximp,"imputed_wine-training-data.csv", row.names = FALSE) #wrote imputed_data to csv file due to processing time taken by missForest and random results. 
```

```{r imputed data frame load from github, echo = FALSE, include=FALSE, cache=TRUE, eval=TRUE}
imputedDfTr <- read.csv("https://raw.githubusercontent.com/ChristopheHunt/DATA-621-Group-1/master/Homework%205/imputed_wine-training-data.csv") %>% mutate(STARS = factor(round(STARS, 0), levels = c(1,2,3,4)))
```

```{r, results='asis', echo = FALSE, cache=TRUE, eval=TRUE}
digits = 1

descriptive <- describe(imputedDfTr %>% dplyr::select(-TARGET),
                        descript = "Table 4 : Imputed Descriptive Statistics", 
                        digits = digits)

latex(descriptive, file = '')
```
\newpage
## Correlation of Variables

### Correlation Matrix

If we modify our data frame to a matrix in our evaluation data set we can further plot a correlation matrix. There are surprisingly few interesting correlations in the data, but the lack of correlation in the data set is in itself interesting. 

* `STARS` has the most positive correlation and strongest correlation with our dependent variable `TARGET`. It is intuitive that the greater the `STARS` value the more cases our wine would sell.

* `LabelAppeal` is the second most correlated with our dependent variable to our dependent variable. It is interesting that the two most correlated variables have less to do with wine quality and more to do with the appearance of a sophisticated wine. 

* The lack of strong correlations is interesting in itself. It is concerning that most variables have nearly no correlation with our dependent variable but represent the actual quality of the wine. We see that public perception of wine is more important than the actual quality of the wine as measured by these variables.    

```{r correlation matrix, fig.cap= "Correlation Plot of Training Data Set", echo = FALSE, fig.height = 7, fig.width= 12, cache=TRUE, eval=TRUE}
imputedDfTrMx <- imputedDfTr                       %>% 
                    map_if(is.integer, as.numeric) %>%
                    map_if(is.factor, as.numeric)  %>%
                    as.data.frame()                %>%
                    as.matrix()

corMx <- cor(imputedDfTrMx , use = "everything",  method = c("spearman"))
corrplot(corMx, order = "hclust", addrect = 10, method = "circle", tl.col = "black", na.label = " ", bg = "gray80")
```
\newpage

# Data Transformation

## Outliers Treatment

### Box Plots of Variables for Winsorizing

Box Plots provide a visualization of the quartiles and outliers of our data set.[^5] Using the box plots, we are can conclude that the variables to be winsorized are Free Sulfur Dioxide, Residual Sugar, and Total Sulfur Dioxide. 

[^5]: "Box Plot." Wikipedia. Wikimedia Foundation, n.d. Web. 24 Nov. 2016.

```{r boxplots, echo = FALSE, cache=TRUE, fig.height=10, fig.width=10}
plotDf <- imputedDfTr %>% 
          dplyr::select(-TARGET) %>% 
          mutate(STARS = as.numeric(STARS)) %>% 
          stack()

plot <- ggplot(plotDf, aes(x = ind, y = values)) + 
          geom_boxplot() +
          facet_wrap(~ind, scales = "free", ncol = 3) +
          theme_minimal() +
          theme(axis.text.x = element_blank()) + 
          ylab(label = "") +
          xlab(label = "") + 
          stat_summary(fun.y = mean, geom = "point", shape = 5, size = 4)
plot
```


### Winsorizing

We chose winsorizing as the method to address outliers. Instead of trimming values, winsorizing uses the interquantile range to replace values that are above or below the interquantile range multiplied by a factor. Those values above or below the range multiplied by the factor are then replaced with max and min value of the interquantile range. Using the factor 2.2 for winsorizing outliers is a method developed my Hoaglin and Iglewicz and published Journal of American Statistical Association in 1987[^4].  

[^4]:Hoaglin, D. C., and Iglewicz, B. (1987), Fine tuning some resistant rules for outlier labeling, Journal of American Statistical Association, 82, 1147-1149.

The below table is the summary results of the winsorizing of the data. 

```{r winsorize dataframe, echo=FALSE, results='asis', cache=TRUE}
winsorize <- function(x, multiple=2.2)
{
  q <- quantile(x)
  iqr <- IQR(x)
  iqrAdjusted <- iqr*multiple

  rangeLow <- q['25%']-iqrAdjusted
  rangeHigh <- q['75%']+iqrAdjusted

  x[x<rangeLow] <- min(x[x>rangeLow])
  x[x>rangeHigh] <- max(x[x<rangeHigh])

  return(x)  

}

wDfTr <- cbind(sapply(c('FreeSulfurDioxide', 'TotalSulfurDioxide', 'ResidualSugar'), 
                      function(x) winsorize(imputedDfTr[,x], multiple=2.2)), 
               subset(imputedDfTr, select = -c(FreeSulfurDioxide, TotalSulfurDioxide, ResidualSugar)))

fwDfTr <- rbind(wDfTr, imputedDfTr$TARGET)

stargazer(fwDfTr, header = FALSE)
```

\newpage

## BoxCox Transformations 

Even after Winsorization we see non-constant variance in the Pearson Residuals for FreeSulferDioxide, TotalSulfurDioxide, and ResidualSugar. The Box-Cox evaluation was completed on these variables, based on the residual plots. In the residual plots, these three variables showed a great deal of non-constant variance because the plots were hyperbolic-shaped. 

```{r residual plots, echo=FALSE, results='asis', fig.width=7, fig.height=5, cache=TRUE, eval=TRUE}
library(car)
fit <- lm(TARGET ~ FreeSulfurDioxide + TotalSulfurDioxide + ResidualSugar + FixedAcidity + VolatileAcidity + CitricAcid + Chlorides + Density + pH + Sulphates + Alcohol + LabelAppeal + STARS, data = fwDfTr)
residualPlots(fit)
```

Using the `BoxCox.lambda` function from the `forecast` package we are able to determine our necessary transformations to our independent variables. 

```{r box cox table, echo=FALSE, cache=TRUE, eval=TRUE, message=FALSE}
l1 <- BoxCox.lambda(as.numeric(fwDfTr$FreeSulfurDioxide))
l2 <- BoxCox.lambda(as.numeric(fwDfTr$TotalSulfurDioxide))
l3 <- BoxCox.lambda(as.numeric(fwDfTr$ResidualSugar))

lamdas <- c(l1, l2, l3)
Variables <- c("Free Sulfur Dioxide", "Total Sulfur Dioxide", "Residual Sugar")

dfBoxCox <- as.data.frame(cbind(lamdas, Variables))

colnames(dfBoxCox) <- c("$\\lambda$", "Variables")

kable(dfBoxCox, align = c("c", "c"))
```

Utilizing transformations based on the lambda value of the BoxCox and rounding to the nearest tenth we further transform our independent variables for our regression models. 

\centering

Box-Cox Transformations [^5]

\setlength{\tabcolsep}{12pt}

\begin{tabular}{ c c }
\hline
$\lambda$ & Y' \\ \hline
-2 &	$Y^{-2}~=~\frac{1}{Y^{2}}$ \\
-1 &	$Y^{-1}~=~\frac{1}{Y^{1}}$ \\
-0.5 &	$Y^{-0.5}~=~\frac{1}{\sqrt{(Y)}}$ \\
0	& $\log(Y)$ \\
.25  & $\sqrt[4]{Y}$\\  
0.5	& $Y^{0.5}~=~\sqrt{(Y)}$ \\
1	& $Y^{1}~=~Y$ \\
1.25 & $Y^{1.25}$ \\
2	& $Y^{2}$ \\

\end{tabular}

\justifying

\centering

\begin{tabular}{ c c }
\hline
variable & variable transformation \\ \hline
\end{tabular}

\justifying

\setlength{\tabcolsep}{6pt}

[^5]: Osborne, Jason W. "Improving your data transformations: Applying the Box-Cox transformation." Practical Assessment, Research & Evaluation 15.12 (2010): 1-9.



\newpage

# Models Built

## Multiple Linear Regression

## Model with All Variables

The first linear regression we generate includes all variables from our data set. As we can see 

```{r linear regression variable all variables, echo=FALSE, results='asis', cache=TRUE}
options(xtable.comment = FALSE)
lm <- lm(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + I(ResidualSugar^1.25) + Chlorides + I(FreeSulfurDioxide^1.25) + TotalSulfurDioxide + Density + pH +  Sulphates + Alcohol + LabelAppeal + STARS, data =  imputedDfTr)

stargazer::stargazer(lm, header = FALSE, no.space = TRUE, style = "qje", font.size = "normalsize", single.row = TRUE, intercept.bottom = FALSE)
```

\newpage

### Model Metrics with all Variables

```{r linear regression model metrics, echo=FALSE, results='asis', cache=TRUE, eval=FALSE}
kable(vif(lm))
influence.measures(lm)
plot(lm$residuals, imputedDfTr$TARGET, ylab = "Residuals", xlab = "Cases Sold", main = "Residual plot of Cases of Wine Sold") 
```

## Model Selection using AIC

### Variable Selection 

Using the R package `MASS` we can utilize the `stepAIC` function in the direction of both to select our best subset of variable for a new wmodel. 

```{r random forest variable selection, echo=FALSE, results='markup', cache=TRUE}
lm <- lm(TARGET ~ ., data = imputedDfTr)
bothlm <- stepAIC(lm, direction = "both", trace = FALSE)
bothlm$anova
```

```{r linear regression variable subset, echo=FALSE, results='asis', cache=TRUE}
lm <- lm(TARGET ~ FixedAcidity + VolatileAcidity + Chlorides + FreeSulfurDioxide + 
    TotalSulfurDioxide + Density + Sulphates + Alcohol + LabelAppeal + 
    STARS, data =  imputedDfTr)

stargazer::stargazer(lm, header = FALSE, no.space = TRUE, style = "qje", font.size = "normalsize", single.row = TRUE, intercept.bottom = FALSE)
```


# Appendix A

## Session Info

```{r, results='asis', echo=FALSE, eval = TRUE}
toLatex(sessionInfo())
```

## Data Dictionary

\footnotesize
```{r data dictionary appendix, eval=TRUE, results='asis', echo=FALSE, cache=TRUE}
pandoc.table(daDict %>% 
      mutate(`Variable Code` = VARIABLE.NAME, Definition = DEFINITION)  %>%
      dplyr::select(`Variable Code`, Definition),
      justify = c("center","left"), emphasize.strong.rows = seq(from = 1, to = nrow(daDict), by = 2),
      table.alignment.rownames = 'centre',style="multiline")
```

## R source code

Please see [Homework 5.rmd](https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Homework%205/Homework%205.Rmd) on GitHub for source code.   

https://github.com/ChristopheHunt/DATA-621-Group-1/blob/master/Homework%205/Homework%205.Rmd

